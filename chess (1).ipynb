{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-5S82XPtOu7",
        "outputId": "42a2c811-76d7-4dfa-9529-304090f5cacf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch: 2.9.0+cu126\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xY9l88EftqKo",
        "outputId": "200ff0bf-f63c-46d9-d2a2-f290dc1d46fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/6.1 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m5.2/6.1 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for chess (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q python-chess pandas pillow tqdm opencv-python matplotlib seaborn scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "1L1FgXV5t6EA",
        "outputId": "5932b134-6da3-4210-88c9-7ff4c2201e23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Upload code.zip...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1e76f12f-8306-4ee5-a9c6-8cfd764f059c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1e76f12f-8306-4ee5-a9c6-8cfd764f059c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving code.zip to code.zip\n",
            "\n",
            "Code uploaded!\n",
            "dataset_tools/:\n",
            "board_detect_and_warp.py  extract_squares.py  make_dataset.py\n",
            "debug_grid.py\t\t  fen_utils.py\t      __pycache__\n",
            "eval.py\t\t\t  __init__.py\t      show_crops.py\n",
            "\n",
            "src/:\n",
            "dataset.py  __init__.py  predict.py   train.py\n",
            "eval.py     model.py\t __pycache__  visualize.py\n"
          ]
        }
      ],
      "source": [
        "# //code.zip\n",
        "\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "print(\"Upload code.zip...\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "with zipfile.ZipFile('code.zip', 'r') as z:\n",
        "    for member in z.namelist():\n",
        "        z.extract(member, 'temp')\n",
        "\n",
        "if os.path.exists('temp'):\n",
        "    for root, dirs, filelist in os.walk('temp'):\n",
        "        for f in filelist:\n",
        "            old_path = os.path.join(root, f)\n",
        "            new_path = os.path.relpath(old_path, 'temp').replace('\\\\', '/')\n",
        "            directory = os.path.dirname(new_path)\n",
        "            if directory:\n",
        "                os.makedirs(directory, exist_ok=True)\n",
        "            shutil.copy(old_path, new_path)\n",
        "    shutil.rmtree('temp')\n",
        "\n",
        "print(\"\\nCode uploaded!\")\n",
        "!ls src/ dataset_tools/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "c-7j4kfnt-WJ",
        "outputId": "25f09b17-7ae4-4b83-c18e-b7a52c845d37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Upload all_games_data.zip (games 2,4,5,6,7)...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f5b08697-2b26-459a-94b9-64873a6d8bf8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f5b08697-2b26-459a-94b9-64873a6d8bf8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving all_games_data.zip to all_games_data.zip\n",
            "\n",
            "============================================================\n",
            "GAMES UPLOADED:\n",
            "============================================================\n",
            "  game2_per_frame: 77 frames\n",
            "  game4_per_frame: 184 frames\n",
            "  game5_per_frame: 109 frames\n",
            "  game6_per_frame: 92 frames\n",
            "  game7_per_frame: 55 frames\n",
            "\n",
            "Total: 517 frames\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "\n",
        "print(\"Upload all_games_data.zip (games 2,4,5,6,7)...\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "with zipfile.ZipFile(list(uploaded.keys())[0], 'r') as z:\n",
        "    for member in z.namelist():\n",
        "        z.extract(member, 'temp')\n",
        "\n",
        "if os.path.exists('temp'):\n",
        "    for root, dirs, filelist in os.walk('temp'):\n",
        "        for f in filelist:\n",
        "            old_path = os.path.join(root, f)\n",
        "            new_path = os.path.relpath(old_path, 'temp').replace('\\\\', '/')\n",
        "            directory = os.path.dirname(new_path)\n",
        "            if directory:\n",
        "                os.makedirs(directory, exist_ok=True)\n",
        "            shutil.copy(old_path, new_path)\n",
        "    shutil.rmtree('temp')\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"GAMES UPLOADED:\")\n",
        "print(\"=\"*60)\n",
        "total_frames = 0\n",
        "for game in sorted(glob.glob('Data/game*_per_frame')):\n",
        "    game_name = os.path.basename(game)\n",
        "    frames = len(glob.glob(f'{game}/tagged_images/*.jpg'))\n",
        "    total_frames += frames\n",
        "    print(f\"  {game_name}: {frames} frames\")\n",
        "print(f\"\\nTotal: {total_frames} frames\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7-Fold Cross-Validation Strategy\n",
        "\n",
        "### Overview\n",
        "This notebook implements **7-fold cross-validation** to evaluate cross-game generalization. Each fold:\n",
        "- **Trains on 6 games** (with 80/20 train/val split within those 6)\n",
        "- **Tests on the 7th game** (100% of that game used for testing)\n",
        "- **Starts with fresh pretrained ResNet50 weights**\n",
        "- **Trains for 8 epochs** with early stopping based on validation accuracy\n",
        "\n",
        "### Key Features\n",
        "1. **Cross-Game Evaluation**: Tests if the model can learn from some games and generalize to completely unseen games\n",
        "2. **Fair Comparison**: Each fold uses the same architecture, hyperparameters, and training procedure\n",
        "3. **Comprehensive Metrics**: \n",
        "   - Per-fold test accuracy (on held-out game)\n",
        "   - Per-fold validation accuracy (on 20% of training games)\n",
        "   - Generalization gap (val vs test performance)\n",
        "   - Per-class accuracy and confusion matrices\n",
        "4. **Statistical Analysis**: Mean, std, min, max across all 7 folds to understand model stability\n",
        "\n",
        "### Training Configuration\n",
        "- **Model**: ResNet50 (pretrained on ImageNet)\n",
        "- **Epochs**: 8 per fold\n",
        "- **Batch Size**: 128\n",
        "- **Learning Rate**: 0.001\n",
        "- **Optimizer**: Adam\n",
        "- **Data Augmentation**: Random horizontal flip, color jitter (training only)\n",
        "- **Input Size**: 224x224 pixels\n",
        "\n",
        "### Expected Outputs\n",
        "- `cross_validation_results.csv` - Detailed results for all 7 folds\n",
        "- `cross_validation_results.png` - Visualizations of performance\n",
        "- `confusion_matrix_fold_X.png` - Confusion matrices for best/worst folds\n",
        "- `checkpoints/fold_X/best_model.pth` - Best model checkpoint for each fold\n",
        "\n",
        "### Interpretation Guide\n",
        "- **Low test accuracy variance** (< 5%) → Good cross-game generalization\n",
        "- **Small generalization gap** (< 3%) → Model doesn't overfit to specific games\n",
        "- **High test accuracy** (> 90%) → Strong performance on unseen games\n",
        "- **Large accuracy range** (> 20%) → Model is sensitive to specific game characteristics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29ZQUJN8z8zF",
        "outputId": "55ea49c8-18ca-471b-b127-fcc1bb456179"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "PER-GAME SPLIT (Each game -> 70/15/15)\n",
            "============================================================\n",
            "\n",
            "game2_per_frame: 77 frames\n",
            "  Train: 53 frames (3,392 sq)\n",
            "  Val:   11 frames (704 sq)\n",
            "  Test:  13 frames (832 sq)\n",
            "\n",
            "game4_per_frame: 184 frames\n",
            "  Train: 128 frames (8,192 sq)\n",
            "  Val:   27 frames (1,728 sq)\n",
            "  Test:  29 frames (1,856 sq)\n",
            "\n",
            "game5_per_frame: 109 frames\n",
            "  Train: 76 frames (4,928 sq)\n",
            "  Val:   16 frames (1,024 sq)\n",
            "  Test:  17 frames (1,088 sq)\n",
            "\n",
            "game6_per_frame: 92 frames\n",
            "  Train: 64 frames (4,096 sq)\n",
            "  Val:   13 frames (832 sq)\n",
            "  Test:  15 frames (960 sq)\n",
            "\n",
            "game7_per_frame: 55 frames\n",
            "  Train: 38 frames (2,496 sq)\n",
            "  Val:   8 frames (512 sq)\n",
            "  Test:  9 frames (576 sq)\n",
            "\n",
            "============================================================\n",
            "COMBINED DATASET\n",
            "============================================================\n",
            "TRAIN: 23,104 squares, 350 frames\n",
            "VAL: 4,800 squares, 75 frames\n",
            "TEST: 5,312 squares, 82 frames\n",
            "\n",
            "Total: 33,216 squares\n",
            "============================================================\n",
            "All games contribute to all three splits\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import json\n",
        "import os\n",
        "from dataset_tools.fen_utils import PIECE_TO_ID, fen_board_to_64_labels, idx_to_square_name\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"PREPARING 7-FOLD CROSS-VALIDATION\")\n",
        "print(\"Each fold: Train on 6 games, Test on 1 game\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "os.makedirs('dataset_out', exist_ok=True)\n",
        "\n",
        "with open('dataset_out/classes.json', 'w') as f:\n",
        "    json.dump({str(v): k for k, v in PIECE_TO_ID.items()}, f, indent=2)\n",
        "\n",
        "# Load all games\n",
        "game_dirs = sorted(glob.glob('Data/*_per_frame'))\n",
        "game_data = {}\n",
        "\n",
        "for game_dir in game_dirs:\n",
        "    game_id = os.path.basename(game_dir)\n",
        "    csv_file = glob.glob(f'{game_dir}/*.csv')\n",
        "\n",
        "    if not csv_file:\n",
        "        continue\n",
        "\n",
        "    df = pd.read_csv(csv_file[0])\n",
        "    frame_col = 'from_frame' if 'from_frame' in df.columns else 'frame_id'\n",
        "\n",
        "    game_rows = []\n",
        "\n",
        "    for _, r in df.iterrows():\n",
        "        frame_id = int(r[frame_col])\n",
        "        fen = r['fen']\n",
        "        labels = fen_board_to_64_labels(fen)\n",
        "\n",
        "        frame_path = f'{game_dir}/tagged_images/frame_{frame_id:06d}.jpg'\n",
        "        if not os.path.exists(frame_path):\n",
        "            continue\n",
        "\n",
        "        for sq in range(64):\n",
        "            game_rows.append({\n",
        "                'frame_path': frame_path,\n",
        "                'game_id': game_id,\n",
        "                'frame_id': frame_id,\n",
        "                'square_idx': sq,\n",
        "                'row': sq // 8,\n",
        "                'col': sq % 8,\n",
        "                'square_name': idx_to_square_name(sq),\n",
        "                'label_id': labels[sq],\n",
        "            })\n",
        "\n",
        "    game_df = pd.DataFrame(game_rows)\n",
        "    game_data[game_id] = game_df\n",
        "    \n",
        "    n_frames = game_df['frame_id'].nunique()\n",
        "    n_squares = len(game_df)\n",
        "    print(f\"{game_id}: {n_frames} frames, {n_squares:,} squares\")\n",
        "\n",
        "print(f\"\\nTotal games loaded: {len(game_data)}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Create 7-fold cross-validation splits\n",
        "fold_manifests = []\n",
        "\n",
        "for fold_idx, test_game in enumerate(game_data.keys()):\n",
        "    print(f\"\\nFold {fold_idx + 1}: Test on {test_game}\")\n",
        "    \n",
        "    # Combine 6 games for training (and validation split)\n",
        "    train_val_dfs = []\n",
        "    for game_id, game_df in game_data.items():\n",
        "        if game_id != test_game:\n",
        "            train_val_dfs.append(game_df.copy())\n",
        "    \n",
        "    train_val_df = pd.concat(train_val_dfs, ignore_index=True)\n",
        "    test_df = game_data[test_game].copy()\n",
        "    \n",
        "    # Split training data into 80% train, 20% val\n",
        "    unique_frames = train_val_df.groupby('game_id')['frame_id'].unique()\n",
        "    \n",
        "    train_frames_list = []\n",
        "    val_frames_list = []\n",
        "    \n",
        "    for game_id, frames in unique_frames.items():\n",
        "        frames = np.array(list(frames))\n",
        "        n_frames = len(frames)\n",
        "        \n",
        "        rng = np.random.RandomState(42)\n",
        "        rng.shuffle(frames)\n",
        "        \n",
        "        n_train = int(0.8 * n_frames)\n",
        "        train_frames_list.extend([(game_id, f) for f in frames[:n_train]])\n",
        "        val_frames_list.extend([(game_id, f) for f in frames[n_train:]])\n",
        "    \n",
        "    train_frame_set = set(train_frames_list)\n",
        "    val_frame_set = set(val_frames_list)\n",
        "    \n",
        "    def assign_split_train_val(row):\n",
        "        key = (row['game_id'], row['frame_id'])\n",
        "        if key in train_frame_set:\n",
        "            return 'train'\n",
        "        elif key in val_frame_set:\n",
        "            return 'val'\n",
        "        else:\n",
        "            return None\n",
        "    \n",
        "    train_val_df['split'] = train_val_df.apply(assign_split_train_val, axis=1)\n",
        "    test_df['split'] = 'test'\n",
        "    \n",
        "    # Combine and save manifest for this fold\n",
        "    fold_df = pd.concat([train_val_df, test_df], ignore_index=True)\n",
        "    fold_df = fold_df.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
        "    \n",
        "    manifest_path = f'dataset_out/fold_{fold_idx + 1}_manifest.csv'\n",
        "    fold_df.to_csv(manifest_path, index=False)\n",
        "    \n",
        "    fold_manifests.append({\n",
        "        'fold': fold_idx + 1,\n",
        "        'test_game': test_game,\n",
        "        'manifest_path': manifest_path,\n",
        "        'train_squares': (fold_df['split'] == 'train').sum(),\n",
        "        'val_squares': (fold_df['split'] == 'val').sum(),\n",
        "        'test_squares': (fold_df['split'] == 'test').sum(),\n",
        "        'train_frames': fold_df[fold_df['split'] == 'train']['frame_id'].nunique(),\n",
        "        'val_frames': fold_df[fold_df['split'] == 'val']['frame_id'].nunique(),\n",
        "        'test_frames': fold_df[fold_df['split'] == 'test']['frame_id'].nunique(),\n",
        "    })\n",
        "    \n",
        "    print(f\"  Train: {fold_manifests[-1]['train_frames']} frames ({fold_manifests[-1]['train_squares']:,} sq)\")\n",
        "    print(f\"  Val:   {fold_manifests[-1]['val_frames']} frames ({fold_manifests[-1]['val_squares']:,} sq)\")\n",
        "    print(f\"  Test:  {fold_manifests[-1]['test_frames']} frames ({fold_manifests[-1]['test_squares']:,} sq) [from {test_game}]\")\n",
        "\n",
        "# Save fold summary\n",
        "fold_summary_df = pd.DataFrame(fold_manifests)\n",
        "fold_summary_df.to_csv('dataset_out/fold_summary.csv', index=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ALL FOLDS PREPARED\")\n",
        "print(\"=\"*60)\n",
        "print(fold_summary_df.to_string(index=False))\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRM-A4lJ0xSf",
        "outputId": "6ad5b611-b5d4-416a-bb63-67da32ca07e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "\n",
            "============================================================\n",
            "Creating dataloaders...\n",
            "============================================================\n",
            "Caching squares from 359 unique images...\n",
            "  Cached 20/359 images...\n",
            "  Cached 40/359 images...\n",
            "  Cached 60/359 images...\n",
            "  Cached 80/359 images...\n",
            "  Cached 100/359 images...\n",
            "  Cached 120/359 images...\n",
            "  Cached 140/359 images...\n",
            "  Cached 160/359 images...\n",
            "  Cached 180/359 images...\n",
            "  Cached 200/359 images...\n",
            "  Cached 220/359 images...\n",
            "  Cached 240/359 images...\n",
            "  Cached 260/359 images...\n",
            "  Cached 280/359 images...\n",
            "  Cached 300/359 images...\n",
            "  Cached 320/359 images...\n",
            "  Cached 340/359 images...\n",
            "✓ Cached 359 images with 22976 squares\n",
            "Dataset initialized: 23104 samples, 13 classes\n",
            "Created train loader: 23104 samples, 180 batches\n",
            "Dataset initialized: 4800 samples, 13 classes\n",
            "Created val loader: 4800 samples, 38 batches\n",
            "Dataset initialized: 5312 samples, 13 classes\n",
            "Created test loader: 5312 samples, 42 batches\n",
            "\n",
            "============================================================\n",
            "Creating model...\n",
            "============================================================\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100% 97.8M/97.8M [00:01<00:00, 76.2MB/s]\n",
            "Created resnet50 model:\n",
            "  Pretrained: True\n",
            "  Num classes: 13\n",
            "  Final layer: Linear(2048 -> 13)\n",
            "Total parameters: 23,534,669\n",
            "\n",
            "============================================================\n",
            "Starting training...\n",
            "============================================================\n",
            "\n",
            "Epoch 1/15\n",
            "------------------------------------------------------------\n",
            "Epoch 1/15 [Train]: 100% 180/180 [03:37<00:00,  1.21s/it, loss=0.1308, acc=89.38%]\n",
            "Val: 100% 38/38 [00:23<00:00,  1.59it/s, loss=0.1487, acc=93.27%]\n",
            "\n",
            "Epoch 1 Summary:\n",
            "  Train Loss: 0.3199 | Train Acc: 89.38%\n",
            "  Val Loss:   0.2147 | Val Acc:   93.27%\n",
            "Saved checkpoint to checkpoints/best_model.pth\n",
            "  New best model! Val Acc: 93.27%\n",
            "Saved checkpoint to checkpoints/latest_model.pth\n",
            "\n",
            "Epoch 2/15\n",
            "------------------------------------------------------------\n",
            "Epoch 2/15 [Train]: 100% 180/180 [03:47<00:00,  1.26s/it, loss=0.0677, acc=95.62%]\n",
            "Val: 100% 38/38 [00:23<00:00,  1.61it/s, loss=0.0721, acc=93.65%]\n",
            "\n",
            "Epoch 2 Summary:\n",
            "  Train Loss: 0.1447 | Train Acc: 95.62%\n",
            "  Val Loss:   0.2839 | Val Acc:   93.65%\n",
            "Saved checkpoint to checkpoints/best_model.pth\n",
            "  New best model! Val Acc: 93.65%\n",
            "Saved checkpoint to checkpoints/latest_model.pth\n",
            "\n",
            "Epoch 3/15\n",
            "------------------------------------------------------------\n",
            "Epoch 3/15 [Train]:  51% 91/180 [01:57<01:54,  1.29s/it, loss=0.0922, acc=96.45%]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/src/train.py\", line 318, in <module>\n",
            "    train(args)\n",
            "  File \"/content/src/train.py\", line 222, in train\n",
            "    train_loss, train_acc = train_epoch(\n",
            "                            ^^^^^^^^^^^^\n",
            "  File \"/content/src/train.py\", line 101, in train_epoch\n",
            "    running_loss += loss.item() * images.size(0)\n",
            "                    ^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"7-FOLD CROSS-VALIDATION TRAINING\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Start Time: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"Random Seed: 42 (for reproducibility)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Load class mapping\n",
        "with open('dataset_out/classes.json', 'r') as f:\n",
        "    classes = json.load(f)\n",
        "num_classes = len(classes)\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "print(f\"Classes: {list(classes.values())}\")\n",
        "\n",
        "# Dataset class\n",
        "class ChessSquareDataset(Dataset):\n",
        "    def __init__(self, manifest_df, transform=None):\n",
        "        self.data = manifest_df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        img_path = row['frame_path']\n",
        "        label = int(row['label_id'])\n",
        "        \n",
        "        # Load image\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        \n",
        "        # Crop square (assuming 8x8 grid)\n",
        "        W, H = img.size\n",
        "        sq_w, sq_h = W // 8, H // 8\n",
        "        col, row_sq = row['col'], row['row']\n",
        "        \n",
        "        left = col * sq_w\n",
        "        top = row_sq * sq_h\n",
        "        right = left + sq_w\n",
        "        bottom = top + sq_h\n",
        "        \n",
        "        img_crop = img.crop((left, top, right, bottom))\n",
        "        \n",
        "        if self.transform:\n",
        "            img_crop = self.transform(img_crop)\n",
        "        \n",
        "        return img_crop, label\n",
        "\n",
        "# Data transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.3),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Training function\n",
        "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for inputs, labels in tqdm(dataloader, desc=\"Training\", leave=False):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        \n",
        "        # Gradient clipping for stability\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "    \n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = 100. * correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "# Validation function\n",
        "def validate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(dataloader, desc=\"Validation\", leave=False):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            \n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "    \n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = 100. * correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "# Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "\n",
        "# Training configuration\n",
        "EPOCHS = 8\n",
        "BATCH_SIZE = 128\n",
        "LR = 0.001\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "print(f\"\\nHyperparameters:\")\n",
        "print(f\"  Epochs: {EPOCHS}\")\n",
        "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"  Learning Rate: {LR}\")\n",
        "print(f\"  Optimizer: Adam\")\n",
        "print(f\"  LR Scheduler: ReduceLROnPlateau (factor=0.5, patience=2)\")\n",
        "print(f\"  Gradient Clipping: max_norm=1.0\")\n",
        "\n",
        "# Results storage\n",
        "all_results = []\n",
        "\n",
        "# Load fold summary\n",
        "fold_summary = pd.read_csv('dataset_out/fold_summary.csv')\n",
        "\n",
        "# Train each fold\n",
        "for fold_idx in range(len(fold_summary)):\n",
        "    fold_info = fold_summary.iloc[fold_idx]\n",
        "    fold_num = fold_info['fold']\n",
        "    test_game = fold_info['test_game']\n",
        "    manifest_path = fold_info['manifest_path']\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\"FOLD {fold_num}/7 - Testing on {test_game}\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Load manifest\n",
        "    manifest_df = pd.read_csv(manifest_path)\n",
        "    train_df = manifest_df[manifest_df['split'] == 'train']\n",
        "    val_df = manifest_df[manifest_df['split'] == 'val']\n",
        "    test_df = manifest_df[manifest_df['split'] == 'test']\n",
        "    \n",
        "    print(f\"Train: {len(train_df):,} squares ({train_df['frame_id'].nunique()} frames)\")\n",
        "    print(f\"Val:   {len(val_df):,} squares ({val_df['frame_id'].nunique()} frames)\")\n",
        "    print(f\"Test:  {len(test_df):,} squares ({test_df['frame_id'].nunique()} frames)\")\n",
        "    \n",
        "    # Create datasets\n",
        "    train_dataset = ChessSquareDataset(train_df, transform=train_transform)\n",
        "    val_dataset = ChessSquareDataset(val_df, transform=val_transform)\n",
        "    test_dataset = ChessSquareDataset(test_df, transform=val_transform)\n",
        "    \n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
        "    \n",
        "    # Initialize model with fresh weights\n",
        "    model = models.resnet50(weights='IMAGENET1K_V1')  # Updated to use weights parameter\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    model = model.to(device)\n",
        "    \n",
        "    # Loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "    # Removed verbose parameter - it's deprecated in newer PyTorch versions\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n",
        "    \n",
        "    # Training loop\n",
        "    fold_start_time = time.time()\n",
        "    best_val_acc = 0.0\n",
        "    best_epoch = 0\n",
        "    epoch_history = []\n",
        "    \n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
        "        \n",
        "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
        "        \n",
        "        epoch_time = time.time() - epoch_start_time\n",
        "        \n",
        "        # Store epoch history\n",
        "        epoch_history.append({\n",
        "            'epoch': epoch + 1,\n",
        "            'train_loss': train_loss,\n",
        "            'train_acc': train_acc,\n",
        "            'val_loss': val_loss,\n",
        "            'val_acc': val_acc,\n",
        "            'lr': optimizer.param_groups[0]['lr'],\n",
        "            'time_sec': epoch_time\n",
        "        })\n",
        "        \n",
        "        print(f\"  Train: Loss={train_loss:.4f}, Acc={train_acc:.2f}%\")\n",
        "        print(f\"  Val:   Loss={val_loss:.4f}, Acc={val_acc:.2f}%\")\n",
        "        print(f\"  Time:  {epoch_time:.1f}s\")\n",
        "        print(f\"  LR:    {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "        \n",
        "        # Update learning rate scheduler\n",
        "        scheduler.step(val_acc)\n",
        "        \n",
        "        # Save best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_epoch = epoch + 1\n",
        "            torch.save({\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'val_acc': val_acc,\n",
        "                'fold': fold_num\n",
        "            }, f'dataset_out/best_model_fold_{fold_num}.pth')\n",
        "            print(f\"  ✓ Best model saved (Val Acc: {val_acc:.2f}%)\")\n",
        "    \n",
        "    # Test on best model\n",
        "    print(f\"\\nLoading best model from epoch {best_epoch}...\")\n",
        "    checkpoint = torch.load(f'dataset_out/best_model_fold_{fold_num}.pth')\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    \n",
        "    test_loss, test_acc = validate(model, test_loader, criterion, device)\n",
        "    \n",
        "    fold_time = time.time() - fold_start_time\n",
        "    \n",
        "    print(f\"\\nFold {fold_num} Results:\")\n",
        "    print(f\"  Best Val Acc:  {best_val_acc:.2f}% (epoch {best_epoch})\")\n",
        "    print(f\"  Test Acc:      {test_acc:.2f}%\")\n",
        "    print(f\"  Total Time:    {fold_time/60:.1f} min\")\n",
        "    \n",
        "    # Store results\n",
        "    all_results.append({\n",
        "        'fold': fold_num,\n",
        "        'test_game': test_game,\n",
        "        'best_val_acc': best_val_acc,\n",
        "        'best_epoch': best_epoch,\n",
        "        'test_acc': test_acc,\n",
        "        'fold_time_min': fold_time / 60,\n",
        "        'epoch_history': epoch_history\n",
        "    })\n",
        "    \n",
        "    # Save fold results\n",
        "    pd.DataFrame(epoch_history).to_csv(f'dataset_out/fold_{fold_num}_history.csv', index=False)\n",
        "\n",
        "# Final summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"7-FOLD CROSS-VALIDATION COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "summary_df = pd.DataFrame([{\n",
        "    'Fold': r['fold'],\n",
        "    'Test Game': r['test_game'],\n",
        "    'Best Val Acc': f\"{r['best_val_acc']:.2f}%\",\n",
        "    'Test Acc': f\"{r['test_acc']:.2f}%\",\n",
        "    'Best Epoch': r['best_epoch']\n",
        "} for r in all_results])\n",
        "\n",
        "print(summary_df.to_string(index=False))\n",
        "\n",
        "mean_test_acc = np.mean([r['test_acc'] for r in all_results])\n",
        "std_test_acc = np.std([r['test_acc'] for r in all_results])\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"MEAN TEST ACCURACY: {mean_test_acc:.2f}% ± {std_test_acc:.2f}%\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Save all results\n",
        "import pickle\n",
        "with open('dataset_out/cross_validation_results.pkl', 'wb') as f:\n",
        "    pickle.dump(all_results, f)\n",
        "\n",
        "print(f\"\\nResults saved to dataset_out/cross_validation_results.pkl\")\n",
        "print(f\"End Time: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load results\n",
        "results_df = pd.read_csv('cross_validation_results.csv')\n",
        "\n",
        "# Create visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Plot 1: Test Accuracy per Fold\n",
        "ax1 = axes[0, 0]\n",
        "bars = ax1.bar(range(1, 8), results_df['test_acc'], color='steelblue', alpha=0.7, edgecolor='black')\n",
        "ax1.axhline(results_df['test_acc'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {results_df[\"test_acc\"].mean():.2f}%')\n",
        "ax1.set_xlabel('Fold (Test Game)', fontsize=12, fontweight='bold')\n",
        "ax1.set_ylabel('Test Accuracy (%)', fontsize=12, fontweight='bold')\n",
        "ax1.set_title('Test Accuracy per Fold\\n(Cross-Game Generalization)', fontsize=14, fontweight='bold')\n",
        "ax1.set_xticks(range(1, 8))\n",
        "ax1.set_xticklabels([f\"F{i}\\n{results_df.iloc[i-1]['test_game'].replace('game', 'G').replace('_per_frame', '')}\" for i in range(1, 8)], fontsize=9)\n",
        "ax1.legend()\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "for i, bar in enumerate(bars):\n",
        "    height = bar.get_height()\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.5, f'{height:.1f}%', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "# Plot 2: Val vs Test Accuracy\n",
        "ax2 = axes[0, 1]\n",
        "x = np.arange(7)\n",
        "width = 0.35\n",
        "bars1 = ax2.bar(x - width/2, results_df['best_val_acc'], width, label='Validation', color='green', alpha=0.7, edgecolor='black')\n",
        "bars2 = ax2.bar(x + width/2, results_df['test_acc'], width, label='Test', color='orange', alpha=0.7, edgecolor='black')\n",
        "ax2.set_xlabel('Fold', fontsize=12, fontweight='bold')\n",
        "ax2.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
        "ax2.set_title('Validation vs Test Accuracy\\n(Generalization Gap)', fontsize=14, fontweight='bold')\n",
        "ax2.set_xticks(x)\n",
        "ax2.set_xticklabels([f'F{i+1}' for i in range(7)])\n",
        "ax2.legend()\n",
        "ax2.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Plot 3: Training Time per Fold\n",
        "ax3 = axes[1, 0]\n",
        "bars = ax3.bar(range(1, 8), results_df['fold_time_min'], color='coral', alpha=0.7, edgecolor='black')\n",
        "ax3.set_xlabel('Fold', fontsize=12, fontweight='bold')\n",
        "ax3.set_ylabel('Time (minutes)', fontsize=12, fontweight='bold')\n",
        "ax3.set_title('Training Time per Fold\\n(8 Epochs)', fontsize=14, fontweight='bold')\n",
        "ax3.set_xticks(range(1, 8))\n",
        "ax3.grid(axis='y', alpha=0.3)\n",
        "for i, bar in enumerate(bars):\n",
        "    height = bar.get_height()\n",
        "    ax3.text(bar.get_x() + bar.get_width()/2., height + 0.2, f'{height:.1f}m', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "# Plot 4: Data Distribution\n",
        "ax4 = axes[1, 1]\n",
        "x = np.arange(7)\n",
        "width = 0.25\n",
        "bars1 = ax4.bar(x - width, results_df['train_samples']/1000, width, label='Train', color='blue', alpha=0.7, edgecolor='black')\n",
        "bars2 = ax4.bar(x, results_df['val_samples']/1000, width, label='Val', color='green', alpha=0.7, edgecolor='black')\n",
        "bars3 = ax4.bar(x + width, results_df['test_samples']/1000, width, label='Test', color='red', alpha=0.7, edgecolor='black')\n",
        "ax4.set_xlabel('Fold', fontsize=12, fontweight='bold')\n",
        "ax4.set_ylabel('Samples (thousands)', fontsize=12, fontweight='bold')\n",
        "ax4.set_title('Data Distribution per Fold\\n(Train/Val/Test Split)', fontsize=14, fontweight='bold')\n",
        "ax4.set_xticks(x)\n",
        "ax4.set_xticklabels([f'F{i+1}' for i in range(7)])\n",
        "ax4.legend()\n",
        "ax4.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('cross_validation_results.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CROSS-GAME GENERALIZATION ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Calculate generalization gap (val - test)\n",
        "results_df['gen_gap'] = results_df['best_val_acc'] - results_df['test_acc']\n",
        "\n",
        "print(\"\\nGeneralization Gap (Val Acc - Test Acc):\")\n",
        "for _, row in results_df.iterrows():\n",
        "    gap_str = f\"+{row['gen_gap']:.2f}%\" if row['gen_gap'] > 0 else f\"{row['gen_gap']:.2f}%\"\n",
        "    status = \"Good\" if abs(row['gen_gap']) < 5 else \"Fair\" if abs(row['gen_gap']) < 10 else \"Poor\"\n",
        "    print(f\"  Fold {int(row['fold'])} ({row['test_game']}): {gap_str} [{status}]\")\n",
        "\n",
        "print(f\"\\nMean Gap: {results_df['gen_gap'].mean():.2f}%\")\n",
        "print(f\"Std Gap:  {results_df['gen_gap'].std():.2f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"KEY INSIGHTS:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"1. Cross-Game Performance: {results_df['test_acc'].mean():.2f}% ± {results_df['test_acc'].std():.2f}%\")\n",
        "print(f\"   → {'Low' if results_df['test_acc'].std() < 5 else 'Moderate' if results_df['test_acc'].std() < 10 else 'High'} variance suggests {'consistent' if results_df['test_acc'].std() < 5 else 'moderate' if results_df['test_acc'].std() < 10 else 'inconsistent'} generalization\")\n",
        "\n",
        "print(f\"\\n2. Generalization Gap: {results_df['gen_gap'].mean():.2f}%\")\n",
        "print(f\"   → {'Excellent' if abs(results_df['gen_gap'].mean()) < 3 else 'Good' if abs(results_df['gen_gap'].mean()) < 5 else 'Fair'} transfer from validation to test\")\n",
        "\n",
        "print(f\"\\n3. Best Performing Game: {results_df.loc[results_df['test_acc'].idxmax(), 'test_game']}\")\n",
        "print(f\"   Test Acc: {results_df['test_acc'].max():.2f}%\")\n",
        "\n",
        "print(f\"\\n4. Worst Performing Game: {results_df.loc[results_df['test_acc'].idxmin(), 'test_game']}\")\n",
        "print(f\"   Test Acc: {results_df['test_acc'].min():.2f}%\")\n",
        "\n",
        "accuracy_range = results_df['test_acc'].max() - results_df['test_acc'].min()\n",
        "print(f\"\\n5. Accuracy Range: {accuracy_range:.2f}%\")\n",
        "print(f\"   → {'Stable' if accuracy_range < 10 else 'Moderate' if accuracy_range < 20 else 'Unstable'} across different games\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RECOMMENDATIONS:\")\n",
        "print(\"=\"*60)\n",
        "if results_df['test_acc'].std() > 10:\n",
        "    print(\"• High variance: Consider data augmentation or more training epochs\")\n",
        "if results_df['gen_gap'].mean() > 5:\n",
        "    print(\"• Large gap: Model may be overfitting to validation games\")\n",
        "if results_df['test_acc'].mean() < 80:\n",
        "    print(\"• Low accuracy: Try different architectures or hyperparameters\")\n",
        "else:\n",
        "    print(\"• Model shows good cross-game generalization!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Per-game detailed analysis\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PER-GAME DETAILED RESULTS:\")\n",
        "print(\"=\"*60)\n",
        "for _, row in results_df.iterrows():\n",
        "    print(f\"\\nFold {int(row['fold'])} - Test Game: {row['test_game']}\")\n",
        "    print(f\"  Training:   {int(row['train_samples']):,} samples from 6 games\")\n",
        "    print(f\"  Validation: {int(row['val_samples']):,} samples (20% of 6 games)\")\n",
        "    print(f\"  Test:       {int(row['test_samples']):,} samples (100% of {row['test_game']})\")\n",
        "    print(f\"  Best Val Acc: {row['best_val_acc']:.2f}%\")\n",
        "    print(f\"  Test Acc:     {row['test_acc']:.2f}%\")\n",
        "    print(f\"  Test Loss:    {row['test_loss']:.4f}\")\n",
        "    print(f\"  Training Time: {row['fold_time_min']:.1f} minutes\")\n",
        "    print(f\"  Generalization: {'✓ Good' if abs(row['gen_gap']) < 5 else '⚠ Fair' if abs(row['gen_gap']) < 10 else '✗ Poor'}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Optional: Per-class accuracy analysis for best and worst folds\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"DETAILED PER-CLASS ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Load classes\n",
        "with open('dataset_out/classes.json', 'r') as f:\n",
        "    classes = json.load(f)\n",
        "num_classes = len(classes)\n",
        "class_names = [classes[str(i)] for i in range(num_classes)]\n",
        "\n",
        "# Load results\n",
        "results_df = pd.read_csv('cross_validation_results.csv')\n",
        "\n",
        "# Analyze best and worst fold\n",
        "best_fold = int(results_df.loc[results_df['test_acc'].idxmax(), 'fold'])\n",
        "worst_fold = int(results_df.loc[results_df['test_acc'].idxmin(), 'fold'])\n",
        "\n",
        "print(f\"\\nAnalyzing:\")\n",
        "print(f\"  Best Fold:  {best_fold} (Test Acc: {results_df.iloc[best_fold-1]['test_acc']:.2f}%)\")\n",
        "print(f\"  Worst Fold: {worst_fold} (Test Acc: {results_df.iloc[worst_fold-1]['test_acc']:.2f}%)\")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def analyze_fold(fold_num):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"FOLD {fold_num} ANALYSIS\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Load manifest\n",
        "    manifest_path = f'dataset_out/fold_{fold_num}_manifest.csv'\n",
        "    manifest_df = pd.read_csv(manifest_path)\n",
        "    test_df = manifest_df[manifest_df['split'] == 'test']\n",
        "    \n",
        "    # Load model\n",
        "    model = models.resnet50(pretrained=False)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    model.load_state_dict(torch.load(f'checkpoints/fold_{fold_num}/best_model.pth'))\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    \n",
        "    # Create dataset\n",
        "    val_transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    \n",
        "    class ChessSquareDataset(Dataset):\n",
        "        def __init__(self, manifest_df, transform=None):\n",
        "            self.data = manifest_df.reset_index(drop=True)\n",
        "            self.transform = transform\n",
        "        \n",
        "        def __len__(self):\n",
        "            return len(self.data)\n",
        "        \n",
        "        def __getitem__(self, idx):\n",
        "            row = self.data.iloc[idx]\n",
        "            img_path = row['frame_path']\n",
        "            label = int(row['label_id'])\n",
        "            \n",
        "            img = Image.open(img_path).convert('RGB')\n",
        "            W, H = img.size\n",
        "            sq_w, sq_h = W // 8, H // 8\n",
        "            col, row_sq = row['col'], row['row']\n",
        "            \n",
        "            left = col * sq_w\n",
        "            top = row_sq * sq_h\n",
        "            right = left + sq_w\n",
        "            bottom = top + sq_h\n",
        "            \n",
        "            img_crop = img.crop((left, top, right, bottom))\n",
        "            \n",
        "            if self.transform:\n",
        "                img_crop = self.transform(img_crop)\n",
        "            \n",
        "            return img_crop, label\n",
        "    \n",
        "    test_dataset = ChessSquareDataset(test_df, transform=val_transform)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
        "    \n",
        "    # Get predictions\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            \n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "    \n",
        "    all_preds = np.array(all_preds)\n",
        "    all_labels = np.array(all_labels)\n",
        "    \n",
        "    # Classification report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    report = classification_report(all_labels, all_preds, target_names=class_names, zero_division=0)\n",
        "    print(report)\n",
        "    \n",
        "    # Per-class accuracy\n",
        "    print(\"\\nPer-Class Accuracy:\")\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        mask = all_labels == i\n",
        "        if mask.sum() > 0:\n",
        "            acc = (all_preds[mask] == all_labels[mask]).sum() / mask.sum() * 100\n",
        "            count = mask.sum()\n",
        "            print(f\"  {class_name:15s}: {acc:5.2f}% ({count:,} samples)\")\n",
        "    \n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    \n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title(f'Confusion Matrix - Fold {fold_num}\\n(Test on {results_df.iloc[fold_num-1][\"test_game\"]})', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('True Label', fontsize=12, fontweight='bold')\n",
        "    plt.xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'confusion_matrix_fold_{fold_num}.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    # Most confused pairs\n",
        "    print(\"\\nMost Confused Class Pairs:\")\n",
        "    confused_pairs = []\n",
        "    for i in range(num_classes):\n",
        "        for j in range(num_classes):\n",
        "            if i != j and cm[i, j] > 0:\n",
        "                confused_pairs.append((class_names[i], class_names[j], cm[i, j]))\n",
        "    \n",
        "    confused_pairs.sort(key=lambda x: x[2], reverse=True)\n",
        "    for true_class, pred_class, count in confused_pairs[:10]:\n",
        "        print(f\"  {true_class:15s} → {pred_class:15s}: {count:4d} times\")\n",
        "\n",
        "# Analyze both folds\n",
        "analyze_fold(best_fold)\n",
        "analyze_fold(worst_fold)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ANALYSIS COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nGenerated files:\")\n",
        "print(\"  - cross_validation_results.csv\")\n",
        "print(\"  - cross_validation_results.png\")\n",
        "print(f\"  - confusion_matrix_fold_{best_fold}.png\")\n",
        "print(f\"  - confusion_matrix_fold_{worst_fold}.png\")\n",
        "print(\"  - checkpoints/fold_X/best_model.pth (for each fold)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5cFmEutYGt5"
      },
      "outputs": [],
      "source": [
        "# python dataset_tools/eval.py --manifest dataset_out/dataset_manifest.csv --preds path/to/preds.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3ROF9GfYhVb"
      },
      "outputs": [],
      "source": [
        "# python -m dataset_tools.make_dataset --data_root Data --out_root dataset_out\n",
        "# Adjust splits/seed: --train_ratio 0.75 --val_ratio 0.05 --seed 1234"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
